[{"content":" Install license-report (https://www.npmjs.com/package/license-report) npm install -g license-report run the script Get-ChildItem -Directory | foreach { $_ \u0026gt;\u0026gt; ./licenses.csv ; license-report --output=csv --only=prod --package=./$_/package.json \u0026gt;\u0026gt; ./licenses.csv } You can use the same idea to run other stuff in subdirectories. Just replace the command. Here is an example of git pull.\nGet-ChildItem -Directory -Force -Recurse *.git | ForEach-Object { cd $_.Parent.FullName; Write-Host $_.Parent.FullName; git pull } ","permalink":"https://artosalminen.github.io/posts/how-to-collect-npm-licenses-from-subdirectories/","summary":" Install license-report (https://www.npmjs.com/package/license-report) npm install -g license-report run the script Get-ChildItem -Directory | foreach { $_ \u0026gt;\u0026gt; ./licenses.csv ; license-report --output=csv --only=prod --package=./$_/package.json \u0026gt;\u0026gt; ./licenses.csv } You can use the same idea to run other stuff in subdirectories. Just replace the command. Here is an example of git pull.\nGet-ChildItem -Directory -Force -Recurse *.git | ForEach-Object { cd $_.Parent.FullName; Write-Host $_.Parent.FullName; git pull } ","title":"How to collect all npm licenses from multiple subdirectories with Powershell"},{"content":"In this blog post, we\u0026rsquo;ll go over how to update a specified item in a nested array inside a Mongoose document.\n##Setting up the environment\nFirst, let\u0026rsquo;s set up the environment by creating a Mongoose schema and model. Here\u0026rsquo;s an example schema that has a nested array of items:\nconst mongoose = require(\u0026#39;mongoose\u0026#39;); const schema = new mongoose.Schema({ items: [{ name: String, quantity: Number }] }); const Model = mongoose.model(\u0026#39;Model\u0026#39;, schema); ##Updating a specified item in a nested array\nTo update a specified item in a nested array, we can use the MongoDB $ operator along with the $set operator. The $ operator is used to specify which item in the array should be updated.\nHere\u0026rsquo;s an example of how to update the quantity field of the first item in the items array with the name equal to 'item1':\nModel.updateOne( {\u0026#39;items.name\u0026#39;: \u0026#39;item1\u0026#39;}, {\u0026#39;$set\u0026#39;: {\u0026#39;items.$.quantity\u0026#39;: 10}}, (err, result) =\u0026gt; { if (err) { console.error(err); } else { console.log(result); } } ); In this example, the Model.updateOne() method is used to update the first document that matches the query {'items.name': 'item1'}. The $ operator is used in the $set operator to specify that the update should be applied to the first item in the items array that matches the query condition. In this case, the quantity field of the item with name equal to 'item1' will be updated to 10.\nNote that the updateOne() method only updates the first document that matches the query. If there are multiple items in the items array with the name equal to 'item1', only the first one will be updated. To update all items that match the query, you can use the updateMany() method instead.\n","permalink":"https://artosalminen.github.io/posts/how-to-update-specified-item-in-nested-mongo-array-with-mongoose/","summary":"In this blog post, we\u0026rsquo;ll go over how to update a specified item in a nested array inside a Mongoose document.\n##Setting up the environment\nFirst, let\u0026rsquo;s set up the environment by creating a Mongoose schema and model. Here\u0026rsquo;s an example schema that has a nested array of items:\nconst mongoose = require(\u0026#39;mongoose\u0026#39;); const schema = new mongoose.Schema({ items: [{ name: String, quantity: Number }] }); const Model = mongoose.model(\u0026#39;Model\u0026#39;, schema); ##Updating a specified item in a nested array","title":"How to update a specified item in a nested array with Mongoose"},{"content":"To access the Syonology NAS ports outside of your local network, you need to set up DDNS, a wildcard certificate, and a reverse proxy to support HTTPS access.\nDDNS Go to Control Panel / External Access / DDNS. Click Add.\nMake the following selections:\nService Provider: Synology Hostname: yourname.synology.me Username/Email: \u0026lt;your email\u0026gt; Password: \u0026lt;make it up\u0026gt; Exteral address: no need to change Wildcard certificate Go to Control Panel / Security / Certificate. Click Add.\nSelect replace existing certificate Select your Synology DDNS from the list Select Get a certificate from Let\u0026rsquo;s Encrypt Check \u0026ldquo;Set as default certificate\u0026rdquo; and click Next Configure the Let\u0026rsquo;s Encrypt certificate lke this\nDomain name: yourname.synology.me Email: \u0026lt;your email\u0026gt; Subject Alternative Name: *.yourname.synology.me and click Done Reverse Proxy Open the Synology Control Panel and navigate to Login Portal / Advanced / Reverse Proxy. Then click Create to create a proxy.\nNext, add a new rule for the proxy. Let\u0026rsquo;s use the rule to access Codeserver port with a subdomain hostname like codeserver.yourname.synology.me.\nSet up the General tab configuration as follows:\nReverse proxy name: codeserver.yourname.synology.me. Source Protocol: HTTPS Source hostname: codeserver.yourname.synology.me Port: 443 Enable HSTS: checked Access control profile: Not set Destination protocol: HTTP Hostname: localhost Port: 8377 Set up Custom Header tab headers:\nHeader name Value Upgrade $http_upgrade Connection $connection_upgrade ","permalink":"https://artosalminen.github.io/posts/how-to-set-up-wildcard-certificate-and-proxy-on-synology-nas/","summary":"To access the Syonology NAS ports outside of your local network, you need to set up DDNS, a wildcard certificate, and a reverse proxy to support HTTPS access.\nDDNS Go to Control Panel / External Access / DDNS. Click Add.\nMake the following selections:\nService Provider: Synology Hostname: yourname.synology.me Username/Email: \u0026lt;your email\u0026gt; Password: \u0026lt;make it up\u0026gt; Exteral address: no need to change Wildcard certificate Go to Control Panel / Security / Certificate.","title":"How to access your Synology NAS services over public Web"},{"content":"The UID and GID values for default user on Synlogy NAS are usually 1026 and 100. There is a very simple way to check the values as follows:\nCreate a new Scheduled task asn User-defined script Name the script whatever you see fit Set it to be not repeating Set it to send run details to your email Write the script: id Not too complex, huh? Run it and soon enough, you will receive the email containing the UID and GID values. These values will be needed to install some Docker containers, for instance the Codeserver.\n","permalink":"https://artosalminen.github.io/posts/how-to-find-uid-and-gid-on-synology-nas/","summary":"The UID and GID values for default user on Synlogy NAS are usually 1026 and 100. There is a very simple way to check the values as follows:\nCreate a new Scheduled task asn User-defined script Name the script whatever you see fit Set it to be not repeating Set it to send run details to your email Write the script: id Not too complex, huh? Run it and soon enough, you will receive the email containing the UID and GID values.","title":"How to find out your UID and GID on Synology NAS"},{"content":"Have you ever missed the VSCode on your tablet? Now there is a solution: run the VSCode on your NAS at home and access it with a browser. That will be possible when you run the Codeserver Docker container on your NAS.\nBefore you do this, you probably want to set up a wildcard certificate and a proxy server on your NAS. That will enable you to access the NAS outside your local network using HTTPS. How to do it, check this: How to Set Up Wildcard Certificate and Reverse Proxy on Synology NAS\nYou will also need to find out your UID and GID. Here are instructions to get those: How to find out your UID and GID on Synology NAS\nAnd after you have sorted those things, you can set up the Codeserver as follows:\nInstall Docker to the Synology NAS from Package Center Create a folder to map the codeserver files into, docker/codeserver works fine Open the Docker app, search for linuxserver/code-server from the registry, and download the image (latest) Set the port mapping as 8377:8443 Adjust the advanced settings as follows: PUID: \u0026lt;your UID\u0026gt; PGID: \u0026lt;your GID\u0026gt; PROXY_DOMAIN: codeserver.\u0026lt;your DDNS domain\u0026gt; PASSWORD: \u0026lt;your very complex password\u0026gt; SUDO_PASSWORD: \u0026lt;your very complex password\u0026gt; TZ: \u0026lt;your timezone, e.g Europe/Helsinki\u0026gt; Map the /config to the folder you created earlier (docker/codeserver) Set automatic restart Run the container Now you should be able to navigate to codeserver.\u0026lt;your DDNS domain\u0026gt; enter the password and enjoy your fresh VSCode on server.\n","permalink":"https://artosalminen.github.io/posts/how-to-set-up-codeserver-on-synology-nas/","summary":"Have you ever missed the VSCode on your tablet? Now there is a solution: run the VSCode on your NAS at home and access it with a browser. That will be possible when you run the Codeserver Docker container on your NAS.\nBefore you do this, you probably want to set up a wildcard certificate and a proxy server on your NAS. That will enable you to access the NAS outside your local network using HTTPS.","title":"How to Set Up a Codeserver on Synology NAS"},{"content":"You might want to access the configuration, for example to set the microservice configuration based on the values from the configuration service.\nOne way to do this is to create an application context from the AppModule.\nconst appContext = await NestFactory.createApplicationContext(BootstrapConfigModule) const configService = appContext.get(ConfigService) const SERVICE_PORT = configService.get(\u0026#39;SERVICE_PORT\u0026#39;) appContext.close() But a better idea is to use a \u0026ldquo;temporary\u0026rdquo; module to avoid double instantiation of the whole app. See a full example below.\nimport { Module } from \u0026#39;@nestjs/common\u0026#39; import { ConfigService } from \u0026#39;@nestjs/config\u0026#39; import { NestFactory } from \u0026#39;@nestjs/core\u0026#39; import { MicroserviceOptions, Transport } from \u0026#39;@nestjs/microservices\u0026#39; import { AppModule } from \u0026#39;./app.module\u0026#39; // Bootstrap configuration module is needed to avoid // doing the DI resolution twice @Module({ providers: [ConfigService], exports: [ConfigService], }) class BootstrapConfigModule {} async function bootstrap() { const appContext = await NestFactory.createApplicationContext(BootstrapConfigModule) const configService = appContext.get(ConfigService) const SERVICE_PORT = configService.get(\u0026#39;SERVICE_PORT\u0026#39;) appContext.close() const app = await NestFactory.createMicroservice\u0026lt;MicroserviceOptions\u0026gt;(AppModule, { transport: Transport.TCP, options: { port: SERVICE_PORT, }, }) await app.listen() } bootstrap() Why would you need to use the configuration service instead of process.env you might ask. Well, while that may work, it doesn\u0026rsquo;t offer any type safety or support for fallbacks.\n","permalink":"https://artosalminen.github.io/posts/how-to-use-config-service-in-nestjs-bootstrap/","summary":"You might want to access the configuration, for example to set the microservice configuration based on the values from the configuration service.\nOne way to do this is to create an application context from the AppModule.\nconst appContext = await NestFactory.createApplicationContext(BootstrapConfigModule) const configService = appContext.get(ConfigService) const SERVICE_PORT = configService.get(\u0026#39;SERVICE_PORT\u0026#39;) appContext.close() But a better idea is to use a \u0026ldquo;temporary\u0026rdquo; module to avoid double instantiation of the whole app. See a full example below.","title":"How to use ConfigService in NestJS in application bootstrap"},{"content":"Let\u0026rsquo;s consider a situation where you have two collections, houses and people. Each house has a collection of key holders, which link to the persons collection with their IDs. Key holders list also holds information when the key was given for the identified person.\nIn bson, the situation in the database looks like this:\n{ \u0026#34;houses\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7e\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Main street 1\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;keyDelivered\u0026#34;: \u0026#34;2022-02-02T02:02:02\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fc\u0026#34; }, { \u0026#34;keyDelivered\u0026#34;: \u0026#34;2021-01-01T01:01:01\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fd\u0026#34; } ] }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7f\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Broadway 3\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;keyDelivered\u0026#34;: \u0026#34;1993-03-03T03:03:03\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fc\u0026#34; } ] } ], \u0026#34;persons\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;), \u0026#34;name\u0026#34;: \u0026#34;Jack Bauer\u0026#34;, }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fd\u0026#34;), \u0026#34;name\u0026#34;: \u0026#34;James Bond\u0026#34;, } ] } You can also do some mapping for the source list, for instance convert foreign keys from strings to ObjectIds.\nThe aggregate pipeline to do the trick looks like this:\n[ { $addFields: { mappedItems: { $map: { input: \u0026#34;$keyHolders\u0026#34;, in: { $mergeObjects: [ \u0026#34;$$this\u0026#34;, { personId: { $toObjectId: \u0026#34;$$this.personId\u0026#34; } } ] } } } } }, { $lookup: { from: \u0026#34;persons\u0026#34;, localField: \u0026#34;mappedItems.personId\u0026#34;, foreignField: \u0026#34;_id\u0026#34;, as: \u0026#34;itemsCollection\u0026#34; } }, { $project: { address: 1, keyHolders: { $map: { input: \u0026#34;$mappedItems\u0026#34;, as: \u0026#34;i\u0026#34;, in: { $mergeObjects: [ \u0026#34;$$i\u0026#34;, { $first: { $filter: { input: \u0026#34;$itemsCollection\u0026#34;, cond: { $eq: [ \u0026#34;$$this._id\u0026#34;, \u0026#34;$$i.personId\u0026#34; ] } } } } ] } } } } } ] And the result:\n[ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7e\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Main street 1\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;), \u0026#34;keyDelivered\u0026#34;: \u0026#34;2022-02-02T02:02:02\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Jack Bauer\u0026#34;, \u0026#34;personId\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;) }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fd\u0026#34;), \u0026#34;keyDelivered\u0026#34;: \u0026#34;2021-01-01T01:01:01\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;James Bond\u0026#34;, \u0026#34;personId\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fd\u0026#34;) } ] }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7f\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Broadway 3\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;), \u0026#34;keyDelivered\u0026#34;: \u0026#34;1993-03-03T03:03:03\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Jack Bauer\u0026#34;, \u0026#34;personId\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;) } ] } ] And here is a Mongo playground link for you: https://mongoplayground.net/p/3s0sFfp7uIY\n","permalink":"https://artosalminen.github.io/posts/how-to-merge-nested-list-to-collection-with-mongo-aggregate/","summary":"Let\u0026rsquo;s consider a situation where you have two collections, houses and people. Each house has a collection of key holders, which link to the persons collection with their IDs. Key holders list also holds information when the key was given for the identified person.\nIn bson, the situation in the database looks like this:\n{ \u0026#34;houses\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7e\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Main street 1\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;keyDelivered\u0026#34;: \u0026#34;2022-02-02T02:02:02\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fc\u0026#34; }, { \u0026#34;keyDelivered\u0026#34;: \u0026#34;2021-01-01T01:01:01\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fd\u0026#34; } ] }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fba17c1c4566e57fafdcd7f\u0026#34;), \u0026#34;address\u0026#34;: \u0026#34;Broadway 3\u0026#34;, \u0026#34;keyHolders\u0026#34;: [ { \u0026#34;keyDelivered\u0026#34;: \u0026#34;1993-03-03T03:03:03\u0026#34;, \u0026#34;personId\u0026#34;: \u0026#34;5fbb5ab778045a985690b5fc\u0026#34; } ] } ], \u0026#34;persons\u0026#34;: [ { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fc\u0026#34;), \u0026#34;name\u0026#34;: \u0026#34;Jack Bauer\u0026#34;, }, { \u0026#34;_id\u0026#34;: ObjectId(\u0026#34;5fbb5ab778045a985690b5fd\u0026#34;), \u0026#34;name\u0026#34;: \u0026#34;James Bond\u0026#34;, } ] } You can also do some mapping for the source list, for instance convert foreign keys from strings to ObjectIds.","title":"How to merge a nested list in Mongo document with another found in adjacent collection"},{"content":"If you need to copy a collection of documents from one Mongo collection to another, you can use the mongodump and mongorestore. But if the source database is in the same instance as the target, then you may be able to take a shortcut with mongosh.\nHere is the script to use:\ndb.\u0026lt;source collection\u0026gt;.find().forEach(function(d){ db.getSiblingDB(\u0026#39;\u0026lt;dest db\u0026gt;\u0026#39;)[\u0026#39;\u0026lt;dest collection\u0026gt;\u0026#39;].insert(d); }); For example, if you are copying all documents from current databases cars collection to a database called another-db\u0026rsquo;s collection vehicles:\ndb.cars.find().forEach(function(d){ db.getSiblingDB(\u0026#39;another-db\u0026#39;)[\u0026#39;vehicles\u0026#39;].insert(d); }); Of course, you can add filters to the find method if you want to copy only subset of documents.\n","permalink":"https://artosalminen.github.io/posts/how-to-copy-collection-to-another-mongo-db-in-mongosh/","summary":"If you need to copy a collection of documents from one Mongo collection to another, you can use the mongodump and mongorestore. But if the source database is in the same instance as the target, then you may be able to take a shortcut with mongosh.\nHere is the script to use:\ndb.\u0026lt;source collection\u0026gt;.find().forEach(function(d){ db.getSiblingDB(\u0026#39;\u0026lt;dest db\u0026gt;\u0026#39;)[\u0026#39;\u0026lt;dest collection\u0026gt;\u0026#39;].insert(d); }); For example, if you are copying all documents from current databases cars collection to a database called another-db\u0026rsquo;s collection vehicles:","title":"How to Copy a Collection of Documents to Another Database with mongosh"},{"content":"So you want to set up a blog. Here is how to do it in 10 minutes or less. For me, it took a little more time, just to make sure for you it would not. And actually, even for me, most of the time was used to write this post.\nSo here we go, you have 40 for each step.\nCreate GitHub account if you do not have one yet Create new GitHub repository named \u0026lt;your GitHub username\u0026gt;.github.io On your local development environment, create a folder to work in, run npm install hugo-bin --save-dev to install Hugo CLI Clone your GitHub repository under the same directory git clone https://github.com/\u0026lt;your username\u0026gt;/\u0026lt;your username\u0026gt;.github.io.git Run npx hugo new site \u0026lt;your username\u0026gt;.github.io Navigate to the repository root directory cd \u0026lt;your username\u0026gt;.github.io Add a theme as Git Submodule: git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod Update config.toml by adding the theme = 'PaperMod' option (and add a name for the site while at it) Also update config.toml with your own baseUrl, e.g. baseURL = 'https://\u0026lt;your GitHub username\u0026gt;.github.io/' Run npx hugo new posts/initial-post.md Edit the initial post and when ready to publish, remove the draft tag Add the following into .github\\workflows\\gh-pages.yml file in the repository name: github pages on: push: branches: - main # Set a branch that will trigger a deployment pull_request: jobs: deploy: runs-on: ubuntu-22.04 steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 if: github.ref == \u0026#39;refs/heads/main\u0026#39; with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public Create a branch named gh-pages in GitHub Check which branch is used for GitHub pages publishing in your GitHub repository, set it to gh-pages Set in GitHub Settings \u0026gt; Actions \u0026gt; General: Workflow permissions to Read and write permissions Push to Git remote using the main branch Make sure the deployment went smoothly, and enjoy the result in https://\u0026lt;your GitHub username\u0026gt;.github.io ","permalink":"https://artosalminen.github.io/posts/how-to-set-up-hugo-blog-in-github-pages/","summary":"So you want to set up a blog. Here is how to do it in 10 minutes or less. For me, it took a little more time, just to make sure for you it would not. And actually, even for me, most of the time was used to write this post.\nSo here we go, you have 40 for each step.\nCreate GitHub account if you do not have one yet Create new GitHub repository named \u0026lt;your GitHub username\u0026gt;.","title":"How to set up a blog with Hugo and GitHub Pages in 10 minutes"}]